{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные библиотеки\n",
    "# Работа с датафреймом\n",
    "import pandas as pd\n",
    "# Линейная алгебра\n",
    "import numpy as np\n",
    "# Рисование графиков\n",
    "import matplotlib.pyplot as plt\n",
    "# Для логов\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Convolution2D, Dropout,MaxPooling2D\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройки генератора случайных чисел\n",
    "from tensorflow import random\n",
    "random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем датасеты\n",
    "train = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-это датасет на котором мы будем тренировать модели\n",
    "# test - это датасет на котором мы будем проверять качество наших моделей\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Редактируем датафреймы.\n",
    "# Тренировочный\n",
    "x_train = train.drop('label',axis=1)/255\n",
    "y_train = train['label']\n",
    "# Тестовый\n",
    "x_test = test.drop('label',axis=1)/255\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем категориальный целевой признак в 0 или 1\n",
    "# Создаем экземляр класса\n",
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    9\n",
       "2    6\n",
       "3    0\n",
       "4    3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вид до преобразования\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_labels = encoder.fit_transform(np.reshape(np.array(y_train), (-1,1))).toarray()\n",
    "y_test_labels = encoder.transform(np.reshape(np.array(y_test), (-1,1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вид после\n",
    "y_train_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим тренировочные данные(x_train и y_train) еще раз на тренировочную\n",
    "# и валидационную.\n",
    "x_TRAIN, x_VALID, y_TRAIN, y_VALID = train_test_split(\n",
    "    x_train,y_train_labels,test_size=0.2,\n",
    "random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель\n",
    "logistick_model = Sequential()\n",
    "# Добавляем в нее полносвязный слой \n",
    "logistick_model.add(Dense(10, input_shape=(784,), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем процесс обучения\n",
    "logistick_model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer='sgd',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем callbacks\n",
    "# Остановка обучения если результат перестал улучшаться\n",
    "early_stopping =  EarlyStopping(patience=2, monitor='val_loss')\n",
    "# Tensorboard\n",
    "# profile_batch чтобы не выскакивала ошибка профилировщика\n",
    "tensorboard = TensorBoard(log_dir=f'Logs\\\\{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                          profile_batch = 100000000)\n",
    "callbacks = [early_stopping,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загружаем веса модели из файла.\n",
    "# logistick_model.load_weights('Logistic_model_stohastic_gradient.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/1000\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 1.6807 - accuracy: 0.5008 - val_loss: 1.3340 - val_accuracy: 0.6340\n",
      "Epoch 2/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 1.1916 - accuracy: 0.6550 - val_loss: 1.0853 - val_accuracy: 0.6725\n",
      "Epoch 3/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 1.0212 - accuracy: 0.6855 - val_loss: 0.9685 - val_accuracy: 0.6960\n",
      "Epoch 4/1000\n",
      "48000/48000 [==============================] - 1s 21us/sample - loss: 0.9306 - accuracy: 0.7064 - val_loss: 0.8983 - val_accuracy: 0.7111\n",
      "Epoch 5/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.8721 - accuracy: 0.7211 - val_loss: 0.8502 - val_accuracy: 0.7225\n",
      "Epoch 6/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.8302 - accuracy: 0.7340 - val_loss: 0.8134 - val_accuracy: 0.7338\n",
      "Epoch 7/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.7980 - accuracy: 0.7437 - val_loss: 0.7855 - val_accuracy: 0.7418\n",
      "Epoch 8/1000\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.7721 - accuracy: 0.7539 - val_loss: 0.7619 - val_accuracy: 0.7520\n",
      "Epoch 9/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.7508 - accuracy: 0.7601 - val_loss: 0.7425 - val_accuracy: 0.7574\n",
      "Epoch 10/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.7325 - accuracy: 0.7664 - val_loss: 0.7258 - val_accuracy: 0.7623\n",
      "Epoch 11/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.7169 - accuracy: 0.7711 - val_loss: 0.7113 - val_accuracy: 0.7691\n",
      "Epoch 12/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.7032 - accuracy: 0.7756 - val_loss: 0.6987 - val_accuracy: 0.7720\n",
      "Epoch 13/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.7804 - val_loss: 0.6874 - val_accuracy: 0.7762\n",
      "Epoch 14/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.6800 - accuracy: 0.7836 - val_loss: 0.6772 - val_accuracy: 0.7779\n",
      "Epoch 15/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6702 - accuracy: 0.7864 - val_loss: 0.6681 - val_accuracy: 0.7807\n",
      "Epoch 16/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6614 - accuracy: 0.7894 - val_loss: 0.6594 - val_accuracy: 0.7814\n",
      "Epoch 17/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6532 - accuracy: 0.7913 - val_loss: 0.6520 - val_accuracy: 0.7847\n",
      "Epoch 18/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.6456 - accuracy: 0.7936 - val_loss: 0.6451 - val_accuracy: 0.7880\n",
      "Epoch 19/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.6387 - accuracy: 0.7955 - val_loss: 0.6385 - val_accuracy: 0.7889\n",
      "Epoch 20/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6324 - accuracy: 0.7978 - val_loss: 0.6321 - val_accuracy: 0.7903\n",
      "Epoch 21/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.6265 - accuracy: 0.7986 - val_loss: 0.6265 - val_accuracy: 0.7928\n",
      "Epoch 22/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.6208 - accuracy: 0.8006 - val_loss: 0.6213 - val_accuracy: 0.7956\n",
      "Epoch 23/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.6156 - accuracy: 0.8021 - val_loss: 0.6162 - val_accuracy: 0.7956\n",
      "Epoch 24/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.6108 - accuracy: 0.8029 - val_loss: 0.6116 - val_accuracy: 0.7976\n",
      "Epoch 25/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.6061 - accuracy: 0.8044 - val_loss: 0.6074 - val_accuracy: 0.7983\n",
      "Epoch 26/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.6017 - accuracy: 0.8061 - val_loss: 0.6036 - val_accuracy: 0.7990\n",
      "Epoch 27/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5977 - accuracy: 0.8069 - val_loss: 0.5993 - val_accuracy: 0.8004\n",
      "Epoch 28/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5937 - accuracy: 0.8083 - val_loss: 0.5956 - val_accuracy: 0.8021\n",
      "Epoch 29/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5901 - accuracy: 0.8096 - val_loss: 0.5920 - val_accuracy: 0.8037\n",
      "Epoch 30/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5865 - accuracy: 0.8103 - val_loss: 0.5890 - val_accuracy: 0.8039\n",
      "Epoch 31/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5832 - accuracy: 0.8114 - val_loss: 0.5856 - val_accuracy: 0.8036\n",
      "Epoch 32/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5798 - accuracy: 0.8124 - val_loss: 0.5826 - val_accuracy: 0.8055\n",
      "Epoch 33/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5769 - accuracy: 0.8132 - val_loss: 0.5797 - val_accuracy: 0.8066\n",
      "Epoch 34/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5739 - accuracy: 0.8148 - val_loss: 0.5767 - val_accuracy: 0.8071\n",
      "Epoch 35/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5710 - accuracy: 0.8150 - val_loss: 0.5744 - val_accuracy: 0.8080\n",
      "Epoch 36/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5684 - accuracy: 0.8160 - val_loss: 0.5715 - val_accuracy: 0.8084\n",
      "Epoch 37/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5658 - accuracy: 0.8166 - val_loss: 0.5690 - val_accuracy: 0.8089\n",
      "Epoch 38/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5632 - accuracy: 0.8170 - val_loss: 0.5666 - val_accuracy: 0.8106\n",
      "Epoch 39/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5608 - accuracy: 0.8179 - val_loss: 0.5643 - val_accuracy: 0.8105\n",
      "Epoch 40/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5585 - accuracy: 0.8184 - val_loss: 0.5621 - val_accuracy: 0.8114\n",
      "Epoch 41/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5562 - accuracy: 0.8188 - val_loss: 0.5600 - val_accuracy: 0.8114\n",
      "Epoch 42/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5541 - accuracy: 0.8195 - val_loss: 0.5580 - val_accuracy: 0.8141\n",
      "Epoch 43/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5520 - accuracy: 0.8199 - val_loss: 0.5561 - val_accuracy: 0.8134\n",
      "Epoch 44/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5500 - accuracy: 0.8201 - val_loss: 0.5540 - val_accuracy: 0.8137\n",
      "Epoch 45/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5480 - accuracy: 0.8205 - val_loss: 0.5520 - val_accuracy: 0.8142\n",
      "Epoch 46/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5461 - accuracy: 0.8207 - val_loss: 0.5511 - val_accuracy: 0.8160\n",
      "Epoch 47/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5443 - accuracy: 0.8214 - val_loss: 0.5487 - val_accuracy: 0.8163\n",
      "Epoch 48/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5425 - accuracy: 0.8219 - val_loss: 0.5472 - val_accuracy: 0.8169\n",
      "Epoch 49/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5408 - accuracy: 0.8226 - val_loss: 0.5454 - val_accuracy: 0.8178\n",
      "Epoch 50/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5391 - accuracy: 0.8229 - val_loss: 0.5437 - val_accuracy: 0.8165\n",
      "Epoch 51/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.5375 - accuracy: 0.8235 - val_loss: 0.5422 - val_accuracy: 0.8172\n",
      "Epoch 52/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5359 - accuracy: 0.8239 - val_loss: 0.5408 - val_accuracy: 0.8184\n",
      "Epoch 53/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5343 - accuracy: 0.8245 - val_loss: 0.5392 - val_accuracy: 0.8183\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5328 - accuracy: 0.8251 - val_loss: 0.5387 - val_accuracy: 0.8179\n",
      "Epoch 55/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5314 - accuracy: 0.8251 - val_loss: 0.5368 - val_accuracy: 0.8192\n",
      "Epoch 56/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5298 - accuracy: 0.8259 - val_loss: 0.5353 - val_accuracy: 0.8187\n",
      "Epoch 57/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5285 - accuracy: 0.8261 - val_loss: 0.5342 - val_accuracy: 0.8205\n",
      "Epoch 58/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5272 - accuracy: 0.8264 - val_loss: 0.5328 - val_accuracy: 0.8203\n",
      "Epoch 59/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5258 - accuracy: 0.8274 - val_loss: 0.5314 - val_accuracy: 0.8203\n",
      "Epoch 60/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5245 - accuracy: 0.8270 - val_loss: 0.5301 - val_accuracy: 0.8201\n",
      "Epoch 61/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5232 - accuracy: 0.8270 - val_loss: 0.5292 - val_accuracy: 0.8214\n",
      "Epoch 62/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5220 - accuracy: 0.8278 - val_loss: 0.5277 - val_accuracy: 0.8207\n",
      "Epoch 63/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5208 - accuracy: 0.8284 - val_loss: 0.5267 - val_accuracy: 0.8219\n",
      "Epoch 64/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5197 - accuracy: 0.8288 - val_loss: 0.5255 - val_accuracy: 0.8218\n",
      "Epoch 65/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5184 - accuracy: 0.8288 - val_loss: 0.5244 - val_accuracy: 0.8218\n",
      "Epoch 66/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5173 - accuracy: 0.8293 - val_loss: 0.5232 - val_accuracy: 0.8220\n",
      "Epoch 67/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5162 - accuracy: 0.8292 - val_loss: 0.5226 - val_accuracy: 0.8233\n",
      "Epoch 68/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.5151 - accuracy: 0.8297 - val_loss: 0.5213 - val_accuracy: 0.8228\n",
      "Epoch 69/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5141 - accuracy: 0.8298 - val_loss: 0.5202 - val_accuracy: 0.8225\n",
      "Epoch 70/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5130 - accuracy: 0.8304 - val_loss: 0.5192 - val_accuracy: 0.8221\n",
      "Epoch 71/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5120 - accuracy: 0.8306 - val_loss: 0.5182 - val_accuracy: 0.8228\n",
      "Epoch 72/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5111 - accuracy: 0.8306 - val_loss: 0.5174 - val_accuracy: 0.8245\n",
      "Epoch 73/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5100 - accuracy: 0.8311 - val_loss: 0.5166 - val_accuracy: 0.8240\n",
      "Epoch 74/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5091 - accuracy: 0.8311 - val_loss: 0.5157 - val_accuracy: 0.8254\n",
      "Epoch 75/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5082 - accuracy: 0.8317 - val_loss: 0.5148 - val_accuracy: 0.8250\n",
      "Epoch 76/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5072 - accuracy: 0.8316 - val_loss: 0.5137 - val_accuracy: 0.8253\n",
      "Epoch 77/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5063 - accuracy: 0.8321 - val_loss: 0.5130 - val_accuracy: 0.8252\n",
      "Epoch 78/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.5054 - accuracy: 0.8321 - val_loss: 0.5122 - val_accuracy: 0.8260\n",
      "Epoch 79/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5046 - accuracy: 0.8327 - val_loss: 0.5113 - val_accuracy: 0.8271\n",
      "Epoch 80/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5037 - accuracy: 0.8329 - val_loss: 0.5106 - val_accuracy: 0.8265\n",
      "Epoch 81/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5028 - accuracy: 0.8331 - val_loss: 0.5098 - val_accuracy: 0.8266\n",
      "Epoch 82/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.5020 - accuracy: 0.8334 - val_loss: 0.5089 - val_accuracy: 0.8268\n",
      "Epoch 83/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5012 - accuracy: 0.8337 - val_loss: 0.5082 - val_accuracy: 0.8268\n",
      "Epoch 84/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.5003 - accuracy: 0.8340 - val_loss: 0.5076 - val_accuracy: 0.8270\n",
      "Epoch 85/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4995 - accuracy: 0.8341 - val_loss: 0.5068 - val_accuracy: 0.8277\n",
      "Epoch 86/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4987 - accuracy: 0.8342 - val_loss: 0.5063 - val_accuracy: 0.8273\n",
      "Epoch 87/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4980 - accuracy: 0.8343 - val_loss: 0.5053 - val_accuracy: 0.8273\n",
      "Epoch 88/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4973 - accuracy: 0.8342 - val_loss: 0.5046 - val_accuracy: 0.8281\n",
      "Epoch 89/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4965 - accuracy: 0.8347 - val_loss: 0.5040 - val_accuracy: 0.8282\n",
      "Epoch 90/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4958 - accuracy: 0.8352 - val_loss: 0.5033 - val_accuracy: 0.8282\n",
      "Epoch 91/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4951 - accuracy: 0.8352 - val_loss: 0.5026 - val_accuracy: 0.8281\n",
      "Epoch 92/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.4944 - accuracy: 0.8352 - val_loss: 0.5022 - val_accuracy: 0.8285\n",
      "Epoch 93/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4937 - accuracy: 0.8357 - val_loss: 0.5015 - val_accuracy: 0.8286\n",
      "Epoch 94/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4930 - accuracy: 0.8358 - val_loss: 0.5006 - val_accuracy: 0.8282\n",
      "Epoch 95/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4923 - accuracy: 0.8360 - val_loss: 0.5000 - val_accuracy: 0.8290\n",
      "Epoch 96/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4916 - accuracy: 0.8361 - val_loss: 0.4993 - val_accuracy: 0.8280\n",
      "Epoch 97/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4910 - accuracy: 0.8363 - val_loss: 0.4988 - val_accuracy: 0.8292\n",
      "Epoch 98/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4903 - accuracy: 0.8364 - val_loss: 0.4983 - val_accuracy: 0.8296\n",
      "Epoch 99/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4896 - accuracy: 0.8368 - val_loss: 0.4978 - val_accuracy: 0.8295\n",
      "Epoch 100/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4891 - accuracy: 0.8367 - val_loss: 0.4973 - val_accuracy: 0.8298\n",
      "Epoch 101/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4884 - accuracy: 0.8373 - val_loss: 0.4966 - val_accuracy: 0.8299\n",
      "Epoch 102/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4878 - accuracy: 0.8370 - val_loss: 0.4959 - val_accuracy: 0.8290\n",
      "Epoch 103/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4873 - accuracy: 0.8374 - val_loss: 0.4957 - val_accuracy: 0.8307\n",
      "Epoch 104/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4865 - accuracy: 0.8372 - val_loss: 0.4948 - val_accuracy: 0.8301\n",
      "Epoch 105/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4860 - accuracy: 0.8376 - val_loss: 0.4942 - val_accuracy: 0.8299\n",
      "Epoch 106/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4854 - accuracy: 0.8379 - val_loss: 0.4938 - val_accuracy: 0.8307\n",
      "Epoch 107/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4848 - accuracy: 0.8378 - val_loss: 0.4933 - val_accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4844 - accuracy: 0.8380 - val_loss: 0.4928 - val_accuracy: 0.8308\n",
      "Epoch 109/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4838 - accuracy: 0.8381 - val_loss: 0.4923 - val_accuracy: 0.8310\n",
      "Epoch 110/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4832 - accuracy: 0.8385 - val_loss: 0.4918 - val_accuracy: 0.8312\n",
      "Epoch 111/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4827 - accuracy: 0.8384 - val_loss: 0.4913 - val_accuracy: 0.8314\n",
      "Epoch 112/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4821 - accuracy: 0.8383 - val_loss: 0.4906 - val_accuracy: 0.8317\n",
      "Epoch 113/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4816 - accuracy: 0.8391 - val_loss: 0.4905 - val_accuracy: 0.8321\n",
      "Epoch 114/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4810 - accuracy: 0.8388 - val_loss: 0.4899 - val_accuracy: 0.8317\n",
      "Epoch 115/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4805 - accuracy: 0.8391 - val_loss: 0.4892 - val_accuracy: 0.8316\n",
      "Epoch 116/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4800 - accuracy: 0.8391 - val_loss: 0.4887 - val_accuracy: 0.8324\n",
      "Epoch 117/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4796 - accuracy: 0.8398 - val_loss: 0.4884 - val_accuracy: 0.8317\n",
      "Epoch 118/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4789 - accuracy: 0.8395 - val_loss: 0.4881 - val_accuracy: 0.8300\n",
      "Epoch 119/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4785 - accuracy: 0.8396 - val_loss: 0.4877 - val_accuracy: 0.8314\n",
      "Epoch 120/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4780 - accuracy: 0.8397 - val_loss: 0.4869 - val_accuracy: 0.8322\n",
      "Epoch 121/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4776 - accuracy: 0.8400 - val_loss: 0.4866 - val_accuracy: 0.8313\n",
      "Epoch 122/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4771 - accuracy: 0.8401 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
      "Epoch 123/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4766 - accuracy: 0.8400 - val_loss: 0.4857 - val_accuracy: 0.8332\n",
      "Epoch 124/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4761 - accuracy: 0.8404 - val_loss: 0.4852 - val_accuracy: 0.8323\n",
      "Epoch 125/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4756 - accuracy: 0.8404 - val_loss: 0.4849 - val_accuracy: 0.8319\n",
      "Epoch 126/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4752 - accuracy: 0.8407 - val_loss: 0.4844 - val_accuracy: 0.8329\n",
      "Epoch 127/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4747 - accuracy: 0.8406 - val_loss: 0.4843 - val_accuracy: 0.8336\n",
      "Epoch 128/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4743 - accuracy: 0.8406 - val_loss: 0.4837 - val_accuracy: 0.8322\n",
      "Epoch 129/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4739 - accuracy: 0.8409 - val_loss: 0.4832 - val_accuracy: 0.8337\n",
      "Epoch 130/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4734 - accuracy: 0.8418 - val_loss: 0.4828 - val_accuracy: 0.8334\n",
      "Epoch 131/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4730 - accuracy: 0.8409 - val_loss: 0.4827 - val_accuracy: 0.8335\n",
      "Epoch 132/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4726 - accuracy: 0.8414 - val_loss: 0.4822 - val_accuracy: 0.8334\n",
      "Epoch 133/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4721 - accuracy: 0.8413 - val_loss: 0.4816 - val_accuracy: 0.8338\n",
      "Epoch 134/1000\n",
      "48000/48000 [==============================] - 1s 15us/sample - loss: 0.4717 - accuracy: 0.8419 - val_loss: 0.4817 - val_accuracy: 0.8336\n",
      "Epoch 135/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4713 - accuracy: 0.8418 - val_loss: 0.4809 - val_accuracy: 0.8332\n",
      "Epoch 136/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4709 - accuracy: 0.8419 - val_loss: 0.4807 - val_accuracy: 0.8339\n",
      "Epoch 137/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4705 - accuracy: 0.8419 - val_loss: 0.4804 - val_accuracy: 0.8347\n",
      "Epoch 138/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4701 - accuracy: 0.8417 - val_loss: 0.4801 - val_accuracy: 0.8344\n",
      "Epoch 139/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4697 - accuracy: 0.8426 - val_loss: 0.4797 - val_accuracy: 0.8344\n",
      "Epoch 140/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4693 - accuracy: 0.8425 - val_loss: 0.4792 - val_accuracy: 0.8346\n",
      "Epoch 141/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4689 - accuracy: 0.8426 - val_loss: 0.4788 - val_accuracy: 0.8344\n",
      "Epoch 142/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4685 - accuracy: 0.8426 - val_loss: 0.4787 - val_accuracy: 0.8351\n",
      "Epoch 143/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4681 - accuracy: 0.8426 - val_loss: 0.4783 - val_accuracy: 0.8353\n",
      "Epoch 144/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4678 - accuracy: 0.8428 - val_loss: 0.4777 - val_accuracy: 0.8349\n",
      "Epoch 145/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4673 - accuracy: 0.8429 - val_loss: 0.4775 - val_accuracy: 0.8345\n",
      "Epoch 146/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4670 - accuracy: 0.8429 - val_loss: 0.4771 - val_accuracy: 0.8346\n",
      "Epoch 147/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4667 - accuracy: 0.8430 - val_loss: 0.4769 - val_accuracy: 0.8353\n",
      "Epoch 148/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4663 - accuracy: 0.8434 - val_loss: 0.4765 - val_accuracy: 0.8350\n",
      "Epoch 149/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4659 - accuracy: 0.8429 - val_loss: 0.4763 - val_accuracy: 0.8353\n",
      "Epoch 150/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4656 - accuracy: 0.8436 - val_loss: 0.4757 - val_accuracy: 0.8358\n",
      "Epoch 151/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4652 - accuracy: 0.8431 - val_loss: 0.4754 - val_accuracy: 0.8352\n",
      "Epoch 152/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4649 - accuracy: 0.8432 - val_loss: 0.4751 - val_accuracy: 0.8355\n",
      "Epoch 153/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4644 - accuracy: 0.8435 - val_loss: 0.4752 - val_accuracy: 0.8359\n",
      "Epoch 154/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4642 - accuracy: 0.8438 - val_loss: 0.4745 - val_accuracy: 0.8347\n",
      "Epoch 155/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4638 - accuracy: 0.8434 - val_loss: 0.4743 - val_accuracy: 0.8363\n",
      "Epoch 156/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4635 - accuracy: 0.8437 - val_loss: 0.4741 - val_accuracy: 0.8360\n",
      "Epoch 157/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4632 - accuracy: 0.8442 - val_loss: 0.4737 - val_accuracy: 0.8363\n",
      "Epoch 158/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4628 - accuracy: 0.8434 - val_loss: 0.4736 - val_accuracy: 0.8363\n",
      "Epoch 159/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4624 - accuracy: 0.8439 - val_loss: 0.4733 - val_accuracy: 0.8363\n",
      "Epoch 160/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4621 - accuracy: 0.8441 - val_loss: 0.4728 - val_accuracy: 0.8359\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4618 - accuracy: 0.8442 - val_loss: 0.4726 - val_accuracy: 0.8372\n",
      "Epoch 162/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4615 - accuracy: 0.8444 - val_loss: 0.4723 - val_accuracy: 0.8372\n",
      "Epoch 163/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4612 - accuracy: 0.8441 - val_loss: 0.4719 - val_accuracy: 0.8365\n",
      "Epoch 164/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4609 - accuracy: 0.8446 - val_loss: 0.4716 - val_accuracy: 0.8371\n",
      "Epoch 165/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4605 - accuracy: 0.8450 - val_loss: 0.4713 - val_accuracy: 0.8372\n",
      "Epoch 166/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4602 - accuracy: 0.8444 - val_loss: 0.4712 - val_accuracy: 0.8378\n",
      "Epoch 167/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4599 - accuracy: 0.8449 - val_loss: 0.4709 - val_accuracy: 0.8369\n",
      "Epoch 168/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4596 - accuracy: 0.8449 - val_loss: 0.4705 - val_accuracy: 0.8370\n",
      "Epoch 169/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4593 - accuracy: 0.8450 - val_loss: 0.4703 - val_accuracy: 0.8377\n",
      "Epoch 170/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4590 - accuracy: 0.8451 - val_loss: 0.4700 - val_accuracy: 0.8376\n",
      "Epoch 171/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4587 - accuracy: 0.8451 - val_loss: 0.4697 - val_accuracy: 0.8364\n",
      "Epoch 172/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4584 - accuracy: 0.8455 - val_loss: 0.4697 - val_accuracy: 0.8378\n",
      "Epoch 173/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4582 - accuracy: 0.8455 - val_loss: 0.4694 - val_accuracy: 0.8378\n",
      "Epoch 174/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4578 - accuracy: 0.8456 - val_loss: 0.4691 - val_accuracy: 0.8379\n",
      "Epoch 175/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4576 - accuracy: 0.8456 - val_loss: 0.4689 - val_accuracy: 0.8382\n",
      "Epoch 176/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4572 - accuracy: 0.8458 - val_loss: 0.4685 - val_accuracy: 0.8371\n",
      "Epoch 177/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4570 - accuracy: 0.8455 - val_loss: 0.4682 - val_accuracy: 0.8370\n",
      "Epoch 178/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4567 - accuracy: 0.8455 - val_loss: 0.4680 - val_accuracy: 0.8379\n",
      "Epoch 179/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4564 - accuracy: 0.8457 - val_loss: 0.4678 - val_accuracy: 0.8377\n",
      "Epoch 180/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4561 - accuracy: 0.8460 - val_loss: 0.4676 - val_accuracy: 0.8379\n",
      "Epoch 181/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4559 - accuracy: 0.8464 - val_loss: 0.4674 - val_accuracy: 0.8369\n",
      "Epoch 182/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4556 - accuracy: 0.8462 - val_loss: 0.4670 - val_accuracy: 0.8375\n",
      "Epoch 183/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4553 - accuracy: 0.8462 - val_loss: 0.4667 - val_accuracy: 0.8378\n",
      "Epoch 184/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4551 - accuracy: 0.8465 - val_loss: 0.4666 - val_accuracy: 0.8385\n",
      "Epoch 185/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4547 - accuracy: 0.8464 - val_loss: 0.4664 - val_accuracy: 0.8371\n",
      "Epoch 186/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4545 - accuracy: 0.8463 - val_loss: 0.4662 - val_accuracy: 0.8386\n",
      "Epoch 187/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4542 - accuracy: 0.8468 - val_loss: 0.4659 - val_accuracy: 0.8380\n",
      "Epoch 188/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4540 - accuracy: 0.8469 - val_loss: 0.4656 - val_accuracy: 0.8380\n",
      "Epoch 189/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4538 - accuracy: 0.8464 - val_loss: 0.4654 - val_accuracy: 0.8375\n",
      "Epoch 190/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4535 - accuracy: 0.8468 - val_loss: 0.4652 - val_accuracy: 0.8383\n",
      "Epoch 191/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4532 - accuracy: 0.8473 - val_loss: 0.4651 - val_accuracy: 0.8373\n",
      "Epoch 192/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4530 - accuracy: 0.8473 - val_loss: 0.4649 - val_accuracy: 0.8386\n",
      "Epoch 193/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4527 - accuracy: 0.8476 - val_loss: 0.4645 - val_accuracy: 0.8382\n",
      "Epoch 194/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4523 - accuracy: 0.8474 - val_loss: 0.4644 - val_accuracy: 0.8381\n",
      "Epoch 195/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4522 - accuracy: 0.8474 - val_loss: 0.4643 - val_accuracy: 0.8386\n",
      "Epoch 196/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4519 - accuracy: 0.8475 - val_loss: 0.4640 - val_accuracy: 0.8388\n",
      "Epoch 197/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4517 - accuracy: 0.8475 - val_loss: 0.4641 - val_accuracy: 0.8402\n",
      "Epoch 198/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4515 - accuracy: 0.8478 - val_loss: 0.4635 - val_accuracy: 0.8382\n",
      "Epoch 199/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4511 - accuracy: 0.8472 - val_loss: 0.4640 - val_accuracy: 0.8395\n",
      "Epoch 200/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4510 - accuracy: 0.8476 - val_loss: 0.4631 - val_accuracy: 0.8393\n",
      "Epoch 201/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4507 - accuracy: 0.8479 - val_loss: 0.4629 - val_accuracy: 0.8388\n",
      "Epoch 202/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4506 - accuracy: 0.8481 - val_loss: 0.4626 - val_accuracy: 0.8382\n",
      "Epoch 203/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4503 - accuracy: 0.8478 - val_loss: 0.4629 - val_accuracy: 0.8400\n",
      "Epoch 204/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4501 - accuracy: 0.8478 - val_loss: 0.4622 - val_accuracy: 0.8388\n",
      "Epoch 205/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4498 - accuracy: 0.8483 - val_loss: 0.4622 - val_accuracy: 0.8394\n",
      "Epoch 206/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4496 - accuracy: 0.8482 - val_loss: 0.4618 - val_accuracy: 0.8392\n",
      "Epoch 207/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4493 - accuracy: 0.8478 - val_loss: 0.4619 - val_accuracy: 0.8395\n",
      "Epoch 208/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4492 - accuracy: 0.8484 - val_loss: 0.4616 - val_accuracy: 0.8395\n",
      "Epoch 209/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4489 - accuracy: 0.8483 - val_loss: 0.4613 - val_accuracy: 0.8393\n",
      "Epoch 210/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4487 - accuracy: 0.8481 - val_loss: 0.4610 - val_accuracy: 0.8394\n",
      "Epoch 211/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4485 - accuracy: 0.8486 - val_loss: 0.4609 - val_accuracy: 0.8393\n",
      "Epoch 212/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4482 - accuracy: 0.8485 - val_loss: 0.4608 - val_accuracy: 0.8389\n",
      "Epoch 213/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4480 - accuracy: 0.8487 - val_loss: 0.4605 - val_accuracy: 0.8394\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4479 - accuracy: 0.8484 - val_loss: 0.4604 - val_accuracy: 0.8391\n",
      "Epoch 215/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4476 - accuracy: 0.8486 - val_loss: 0.4602 - val_accuracy: 0.8393\n",
      "Epoch 216/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4473 - accuracy: 0.8490 - val_loss: 0.4600 - val_accuracy: 0.8395\n",
      "Epoch 217/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4472 - accuracy: 0.8489 - val_loss: 0.4598 - val_accuracy: 0.8390\n",
      "Epoch 218/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4469 - accuracy: 0.8491 - val_loss: 0.4596 - val_accuracy: 0.8397\n",
      "Epoch 219/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4467 - accuracy: 0.8491 - val_loss: 0.4595 - val_accuracy: 0.8397\n",
      "Epoch 220/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4465 - accuracy: 0.8490 - val_loss: 0.4594 - val_accuracy: 0.8397\n",
      "Epoch 221/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4463 - accuracy: 0.8492 - val_loss: 0.4594 - val_accuracy: 0.8401\n",
      "Epoch 222/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4461 - accuracy: 0.8497 - val_loss: 0.4591 - val_accuracy: 0.8401\n",
      "Epoch 223/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4459 - accuracy: 0.8497 - val_loss: 0.4588 - val_accuracy: 0.8399\n",
      "Epoch 224/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4457 - accuracy: 0.8492 - val_loss: 0.4588 - val_accuracy: 0.8400\n",
      "Epoch 225/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4455 - accuracy: 0.8491 - val_loss: 0.4585 - val_accuracy: 0.8407\n",
      "Epoch 226/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4453 - accuracy: 0.8493 - val_loss: 0.4583 - val_accuracy: 0.8401\n",
      "Epoch 227/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4451 - accuracy: 0.8498 - val_loss: 0.4581 - val_accuracy: 0.8404\n",
      "Epoch 228/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4449 - accuracy: 0.8496 - val_loss: 0.4580 - val_accuracy: 0.8398\n",
      "Epoch 229/1000\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.4447 - accuracy: 0.8497 - val_loss: 0.4577 - val_accuracy: 0.8397\n",
      "Epoch 230/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4446 - accuracy: 0.8494 - val_loss: 0.4575 - val_accuracy: 0.8398\n",
      "Epoch 231/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4443 - accuracy: 0.8499 - val_loss: 0.4574 - val_accuracy: 0.8399\n",
      "Epoch 232/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4441 - accuracy: 0.8500 - val_loss: 0.4573 - val_accuracy: 0.8407\n",
      "Epoch 233/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4439 - accuracy: 0.8498 - val_loss: 0.4571 - val_accuracy: 0.8405\n",
      "Epoch 234/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4436 - accuracy: 0.8500 - val_loss: 0.4571 - val_accuracy: 0.8409\n",
      "Epoch 235/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4436 - accuracy: 0.8505 - val_loss: 0.4569 - val_accuracy: 0.8408\n",
      "Epoch 236/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4433 - accuracy: 0.8501 - val_loss: 0.4566 - val_accuracy: 0.8408\n",
      "Epoch 237/1000\n",
      "48000/48000 [==============================] - 1s 12us/sample - loss: 0.4431 - accuracy: 0.8504 - val_loss: 0.4567 - val_accuracy: 0.8410\n",
      "Epoch 238/1000\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.4430 - accuracy: 0.8505 - val_loss: 0.4566 - val_accuracy: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x170497e708>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "logistick_model.fit(x_TRAIN.values, y_TRAIN, batch_size=500,\n",
    "                    validation_data=(x_VALID.values, y_VALID),\n",
    "                       callbacks=callbacks, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Сохраняем  полученные веса модели\n",
    "# logistick_model.save_weights('Logistic_model_stohastic_gradient.h5',\n",
    "#                              save_format ='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### График качества модели(метрика accuracy) на тренировочной и  валидационной выборках в зависимости от количества эпох.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='data/logistick_model_accuracy_2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем качество модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.4561 - accuracy: 0.8489\n",
      "Логистическая регрессия \n",
      "Accuracy на тестовой выборке равна: 0.8489\n"
     ]
    }
   ],
   "source": [
    "_, score = logistick_model.evaluate(x_test.values, y_test_labels)\n",
    "print(\"Логистическая регрессия \\nAccuracy на тестовой выборке равна: {0:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель показывает похожие результаты как валидационной выборке, так и на тестовой. Что может говорить о том что она не переобучилась на тренировочных данных и адекватно может работать на новых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Полносвязная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель и добавляем слои\n",
    "model_fcnn = Sequential()\n",
    "model_fcnn.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model_fcnn.add(Dropout(0.25))\n",
    "model_fcnn.add(Dense(512, activation='relu'))\n",
    "model_fcnn.add(Dropout(0.25))\n",
    "model_fcnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем процесс обучения\n",
    "model_fcnn.compile(loss='categorical_crossentropy',\n",
    "                        optimizer='sgd',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем callbacks\n",
    "# Остановка обучения если результат перестал улучшаться\n",
    "early_stopping =  EarlyStopping(patience=2, monitor='val_loss')\n",
    "# Tensorboard\n",
    "# profile_batch чтобы не выскакивала ошибка профилировщика\n",
    "tensorboard = TensorBoard(log_dir=f'Logs\\\\{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                          profile_batch = 100000000)\n",
    "callbacks = [early_stopping,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 1.8121 - accuracy: 0.4273 - val_loss: 1.3058 - val_accuracy: 0.6559\n",
      "Epoch 2/1000\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 1.2070 - accuracy: 0.6235 - val_loss: 0.9616 - val_accuracy: 0.6932\n",
      "Epoch 3/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.9895 - accuracy: 0.6695 - val_loss: 0.8303 - val_accuracy: 0.7253\n",
      "Epoch 4/1000\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.8879 - accuracy: 0.6964 - val_loss: 0.7585 - val_accuracy: 0.7448\n",
      "Epoch 5/1000\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.8220 - accuracy: 0.7219 - val_loss: 0.7118 - val_accuracy: 0.7584\n",
      "Epoch 6/1000\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.7737 - accuracy: 0.7387 - val_loss: 0.6766 - val_accuracy: 0.7667\n",
      "Epoch 7/1000\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.7439 - accuracy: 0.7483 - val_loss: 0.6518 - val_accuracy: 0.7758\n",
      "Epoch 8/1000\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.7106 - accuracy: 0.7585 - val_loss: 0.6278 - val_accuracy: 0.7860\n",
      "Epoch 9/1000\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.6896 - accuracy: 0.7672 - val_loss: 0.6114 - val_accuracy: 0.7909\n",
      "Epoch 10/1000\n",
      "48000/48000 [==============================] - 4s 84us/sample - loss: 0.6721 - accuracy: 0.7695 - val_loss: 0.5964 - val_accuracy: 0.7952\n",
      "Epoch 11/1000\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.6515 - accuracy: 0.7771 - val_loss: 0.5811 - val_accuracy: 0.8007\n",
      "Epoch 12/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.6407 - accuracy: 0.7825 - val_loss: 0.5704 - val_accuracy: 0.8042\n",
      "Epoch 13/1000\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.6230 - accuracy: 0.7896 - val_loss: 0.5596 - val_accuracy: 0.8074\n",
      "Epoch 14/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.6150 - accuracy: 0.7900 - val_loss: 0.5516 - val_accuracy: 0.8099\n",
      "Epoch 15/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.6035 - accuracy: 0.7939 - val_loss: 0.5442 - val_accuracy: 0.8114\n",
      "Epoch 16/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.5933 - accuracy: 0.7973 - val_loss: 0.5358 - val_accuracy: 0.8153\n",
      "Epoch 17/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5864 - accuracy: 0.7985 - val_loss: 0.5297 - val_accuracy: 0.8170\n",
      "Epoch 18/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.5781 - accuracy: 0.8009 - val_loss: 0.5215 - val_accuracy: 0.8198\n",
      "Epoch 19/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5696 - accuracy: 0.8050 - val_loss: 0.5189 - val_accuracy: 0.8192\n",
      "Epoch 20/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5649 - accuracy: 0.8057 - val_loss: 0.5115 - val_accuracy: 0.8227\n",
      "Epoch 21/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.5578 - accuracy: 0.8096 - val_loss: 0.5068 - val_accuracy: 0.8242\n",
      "Epoch 22/1000\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.5488 - accuracy: 0.8109 - val_loss: 0.5018 - val_accuracy: 0.8249\n",
      "Epoch 23/1000\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.5464 - accuracy: 0.8129 - val_loss: 0.4966 - val_accuracy: 0.8272\n",
      "Epoch 24/1000\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.5407 - accuracy: 0.8125 - val_loss: 0.4924 - val_accuracy: 0.8286\n",
      "Epoch 25/1000\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.5346 - accuracy: 0.8144 - val_loss: 0.4885 - val_accuracy: 0.8303\n",
      "Epoch 26/1000\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.5317 - accuracy: 0.8167 - val_loss: 0.4870 - val_accuracy: 0.8305\n",
      "Epoch 27/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5266 - accuracy: 0.8180 - val_loss: 0.4815 - val_accuracy: 0.8305\n",
      "Epoch 28/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5210 - accuracy: 0.8198 - val_loss: 0.4781 - val_accuracy: 0.8320\n",
      "Epoch 29/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.5184 - accuracy: 0.8217 - val_loss: 0.4744 - val_accuracy: 0.8340\n",
      "Epoch 30/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.5141 - accuracy: 0.8230 - val_loss: 0.4736 - val_accuracy: 0.8342\n",
      "Epoch 31/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.5117 - accuracy: 0.8229 - val_loss: 0.4703 - val_accuracy: 0.8350\n",
      "Epoch 32/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.5037 - accuracy: 0.8244 - val_loss: 0.4671 - val_accuracy: 0.8349\n",
      "Epoch 33/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.5038 - accuracy: 0.8270 - val_loss: 0.4643 - val_accuracy: 0.8368\n",
      "Epoch 34/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.5018 - accuracy: 0.8259 - val_loss: 0.4609 - val_accuracy: 0.8383\n",
      "Epoch 35/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.4971 - accuracy: 0.8279 - val_loss: 0.4608 - val_accuracy: 0.8392\n",
      "Epoch 36/1000\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.4941 - accuracy: 0.8290 - val_loss: 0.4568 - val_accuracy: 0.8395\n",
      "Epoch 37/1000\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.4911 - accuracy: 0.8305 - val_loss: 0.4548 - val_accuracy: 0.8404\n",
      "Epoch 38/1000\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.4863 - accuracy: 0.8319 - val_loss: 0.4523 - val_accuracy: 0.8403\n",
      "Epoch 39/1000\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.4840 - accuracy: 0.8316 - val_loss: 0.4495 - val_accuracy: 0.8418\n",
      "Epoch 40/1000\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.4828 - accuracy: 0.8319 - val_loss: 0.4483 - val_accuracy: 0.8416\n",
      "Epoch 41/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.4803 - accuracy: 0.8334 - val_loss: 0.4460 - val_accuracy: 0.8413\n",
      "Epoch 42/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.4779 - accuracy: 0.8344 - val_loss: 0.4434 - val_accuracy: 0.8435\n",
      "Epoch 43/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.4745 - accuracy: 0.8350 - val_loss: 0.4420 - val_accuracy: 0.8428\n",
      "Epoch 44/1000\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.4729 - accuracy: 0.8340 - val_loss: 0.4391 - val_accuracy: 0.8436\n",
      "Epoch 45/1000\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.4683 - accuracy: 0.8356 - val_loss: 0.4369 - val_accuracy: 0.8446\n",
      "Epoch 46/1000\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.4678 - accuracy: 0.8360 - val_loss: 0.4383 - val_accuracy: 0.8443\n",
      "Epoch 47/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.4668 - accuracy: 0.8376 - val_loss: 0.4346 - val_accuracy: 0.8443\n",
      "Epoch 48/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4642 - accuracy: 0.8376 - val_loss: 0.4329 - val_accuracy: 0.8451\n",
      "Epoch 49/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.4597 - accuracy: 0.8402 - val_loss: 0.4310 - val_accuracy: 0.8466\n",
      "Epoch 50/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.4588 - accuracy: 0.8400 - val_loss: 0.4288 - val_accuracy: 0.8468\n",
      "Epoch 51/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4588 - accuracy: 0.8403 - val_loss: 0.4278 - val_accuracy: 0.8468\n",
      "Epoch 52/1000\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.4531 - accuracy: 0.8419 - val_loss: 0.4263 - val_accuracy: 0.8478\n",
      "Epoch 53/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4515 - accuracy: 0.8432 - val_loss: 0.4242 - val_accuracy: 0.8478\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.4514 - accuracy: 0.8416 - val_loss: 0.4260 - val_accuracy: 0.8478\n",
      "Epoch 55/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4495 - accuracy: 0.8430 - val_loss: 0.4224 - val_accuracy: 0.8486\n",
      "Epoch 56/1000\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.4464 - accuracy: 0.8439 - val_loss: 0.4205 - val_accuracy: 0.8491\n",
      "Epoch 57/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.4457 - accuracy: 0.8446 - val_loss: 0.4192 - val_accuracy: 0.8504\n",
      "Epoch 58/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.4422 - accuracy: 0.8463 - val_loss: 0.4181 - val_accuracy: 0.8507\n",
      "Epoch 59/1000\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.4419 - accuracy: 0.8447 - val_loss: 0.4175 - val_accuracy: 0.8506\n",
      "Epoch 60/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.4405 - accuracy: 0.8453 - val_loss: 0.4144 - val_accuracy: 0.8524\n",
      "Epoch 61/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.4402 - accuracy: 0.8454 - val_loss: 0.4150 - val_accuracy: 0.8520\n",
      "Epoch 62/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4364 - accuracy: 0.8475 - val_loss: 0.4122 - val_accuracy: 0.8523\n",
      "Epoch 63/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4353 - accuracy: 0.8459 - val_loss: 0.4102 - val_accuracy: 0.8548\n",
      "Epoch 64/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4355 - accuracy: 0.8470 - val_loss: 0.4095 - val_accuracy: 0.8541\n",
      "Epoch 65/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.4320 - accuracy: 0.8478 - val_loss: 0.4083 - val_accuracy: 0.8537\n",
      "Epoch 66/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.4307 - accuracy: 0.8491 - val_loss: 0.4067 - val_accuracy: 0.8552\n",
      "Epoch 67/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4299 - accuracy: 0.8491 - val_loss: 0.4070 - val_accuracy: 0.8538\n",
      "Epoch 68/1000\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.4278 - accuracy: 0.8500 - val_loss: 0.4043 - val_accuracy: 0.8551\n",
      "Epoch 69/1000\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.4254 - accuracy: 0.8502 - val_loss: 0.4028 - val_accuracy: 0.8567\n",
      "Epoch 70/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4238 - accuracy: 0.8513 - val_loss: 0.4025 - val_accuracy: 0.8564\n",
      "Epoch 71/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.4243 - accuracy: 0.8510 - val_loss: 0.4010 - val_accuracy: 0.8569\n",
      "Epoch 72/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4201 - accuracy: 0.8521 - val_loss: 0.4007 - val_accuracy: 0.8568\n",
      "Epoch 73/1000\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.4201 - accuracy: 0.8511 - val_loss: 0.3998 - val_accuracy: 0.8578\n",
      "Epoch 74/1000\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.4177 - accuracy: 0.8531 - val_loss: 0.3982 - val_accuracy: 0.8582\n",
      "Epoch 75/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.4165 - accuracy: 0.8535 - val_loss: 0.3972 - val_accuracy: 0.8577\n",
      "Epoch 76/1000\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.4158 - accuracy: 0.8533 - val_loss: 0.3953 - val_accuracy: 0.8592\n",
      "Epoch 77/1000\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 0.4152 - accuracy: 0.8555 - val_loss: 0.3955 - val_accuracy: 0.8582\n",
      "Epoch 78/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.4134 - accuracy: 0.8542 - val_loss: 0.3940 - val_accuracy: 0.8592\n",
      "Epoch 79/1000\n",
      "48000/48000 [==============================] - 4s 94us/sample - loss: 0.4112 - accuracy: 0.8555 - val_loss: 0.3934 - val_accuracy: 0.8597\n",
      "Epoch 80/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.4131 - accuracy: 0.8547 - val_loss: 0.3924 - val_accuracy: 0.8597\n",
      "Epoch 81/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4092 - accuracy: 0.8556 - val_loss: 0.3915 - val_accuracy: 0.8599\n",
      "Epoch 82/1000\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.4079 - accuracy: 0.8585 - val_loss: 0.3896 - val_accuracy: 0.8607\n",
      "Epoch 83/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4073 - accuracy: 0.8566 - val_loss: 0.3889 - val_accuracy: 0.8610\n",
      "Epoch 84/1000\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.4081 - accuracy: 0.8566 - val_loss: 0.3880 - val_accuracy: 0.8612\n",
      "Epoch 85/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4053 - accuracy: 0.8571 - val_loss: 0.3870 - val_accuracy: 0.8612\n",
      "Epoch 86/1000\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.4037 - accuracy: 0.8574 - val_loss: 0.3868 - val_accuracy: 0.8624\n",
      "Epoch 87/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.4019 - accuracy: 0.8579 - val_loss: 0.3849 - val_accuracy: 0.8630\n",
      "Epoch 88/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4011 - accuracy: 0.8587 - val_loss: 0.3845 - val_accuracy: 0.8629\n",
      "Epoch 89/1000\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.4010 - accuracy: 0.8589 - val_loss: 0.3836 - val_accuracy: 0.8627\n",
      "Epoch 90/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.4010 - accuracy: 0.8584 - val_loss: 0.3829 - val_accuracy: 0.8639\n",
      "Epoch 91/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.3983 - accuracy: 0.8601 - val_loss: 0.3817 - val_accuracy: 0.8639\n",
      "Epoch 92/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3979 - accuracy: 0.8600 - val_loss: 0.3817 - val_accuracy: 0.8632\n",
      "Epoch 93/1000\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.3959 - accuracy: 0.8604 - val_loss: 0.3800 - val_accuracy: 0.8643\n",
      "Epoch 94/1000\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.3940 - accuracy: 0.8602 - val_loss: 0.3796 - val_accuracy: 0.8646\n",
      "Epoch 95/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3944 - accuracy: 0.8601 - val_loss: 0.3790 - val_accuracy: 0.8641\n",
      "Epoch 96/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3938 - accuracy: 0.8615 - val_loss: 0.3776 - val_accuracy: 0.8645\n",
      "Epoch 97/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.3937 - accuracy: 0.8600 - val_loss: 0.3768 - val_accuracy: 0.8649\n",
      "Epoch 98/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.3899 - accuracy: 0.8624 - val_loss: 0.3768 - val_accuracy: 0.8652\n",
      "Epoch 99/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.3901 - accuracy: 0.8626 - val_loss: 0.3764 - val_accuracy: 0.8646\n",
      "Epoch 100/1000\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.3897 - accuracy: 0.8637 - val_loss: 0.3764 - val_accuracy: 0.8657\n",
      "Epoch 101/1000\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.3882 - accuracy: 0.8632 - val_loss: 0.3748 - val_accuracy: 0.8649\n",
      "Epoch 102/1000\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.3870 - accuracy: 0.8634 - val_loss: 0.3727 - val_accuracy: 0.8657\n",
      "Epoch 103/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.3876 - accuracy: 0.8634 - val_loss: 0.3738 - val_accuracy: 0.8662\n",
      "Epoch 104/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3857 - accuracy: 0.8637 - val_loss: 0.3721 - val_accuracy: 0.8662\n",
      "Epoch 105/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.3842 - accuracy: 0.8658 - val_loss: 0.3708 - val_accuracy: 0.8662\n",
      "Epoch 106/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.3833 - accuracy: 0.8647 - val_loss: 0.3704 - val_accuracy: 0.8665\n",
      "Epoch 107/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.3843 - accuracy: 0.8641 - val_loss: 0.3700 - val_accuracy: 0.8669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3824 - accuracy: 0.8641 - val_loss: 0.3705 - val_accuracy: 0.8664\n",
      "Epoch 109/1000\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.3820 - accuracy: 0.8647 - val_loss: 0.3693 - val_accuracy: 0.8671\n",
      "Epoch 110/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3797 - accuracy: 0.8652 - val_loss: 0.3680 - val_accuracy: 0.8683\n",
      "Epoch 111/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3798 - accuracy: 0.8674 - val_loss: 0.3678 - val_accuracy: 0.8672\n",
      "Epoch 112/1000\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.3790 - accuracy: 0.8657 - val_loss: 0.3670 - val_accuracy: 0.8677\n",
      "Epoch 113/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3763 - accuracy: 0.8670 - val_loss: 0.3666 - val_accuracy: 0.8687\n",
      "Epoch 114/1000\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.3757 - accuracy: 0.8678 - val_loss: 0.3652 - val_accuracy: 0.8689\n",
      "Epoch 115/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3758 - accuracy: 0.8673 - val_loss: 0.3646 - val_accuracy: 0.8677\n",
      "Epoch 116/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3757 - accuracy: 0.8668 - val_loss: 0.3641 - val_accuracy: 0.8680\n",
      "Epoch 117/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3767 - accuracy: 0.8664 - val_loss: 0.3639 - val_accuracy: 0.8686\n",
      "Epoch 118/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.3727 - accuracy: 0.8664 - val_loss: 0.3625 - val_accuracy: 0.8691\n",
      "Epoch 119/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.3741 - accuracy: 0.8673 - val_loss: 0.3632 - val_accuracy: 0.8692\n",
      "Epoch 120/1000\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 0.3724 - accuracy: 0.8683 - val_loss: 0.3618 - val_accuracy: 0.8694\n",
      "Epoch 121/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3721 - accuracy: 0.8690 - val_loss: 0.3614 - val_accuracy: 0.8692\n",
      "Epoch 122/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3724 - accuracy: 0.8684 - val_loss: 0.3607 - val_accuracy: 0.8705\n",
      "Epoch 123/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.3682 - accuracy: 0.8687 - val_loss: 0.3603 - val_accuracy: 0.8708\n",
      "Epoch 124/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3708 - accuracy: 0.8696 - val_loss: 0.3593 - val_accuracy: 0.8704\n",
      "Epoch 125/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3668 - accuracy: 0.8701 - val_loss: 0.3591 - val_accuracy: 0.8703\n",
      "Epoch 126/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.3664 - accuracy: 0.8703 - val_loss: 0.3585 - val_accuracy: 0.8698\n",
      "Epoch 127/1000\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 0.3684 - accuracy: 0.8687 - val_loss: 0.3578 - val_accuracy: 0.8709\n",
      "Epoch 128/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3652 - accuracy: 0.8709 - val_loss: 0.3569 - val_accuracy: 0.8698\n",
      "Epoch 129/1000\n",
      "48000/48000 [==============================] - 4s 90us/sample - loss: 0.3662 - accuracy: 0.8704 - val_loss: 0.3565 - val_accuracy: 0.8710\n",
      "Epoch 130/1000\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.3633 - accuracy: 0.8726 - val_loss: 0.3568 - val_accuracy: 0.8702\n",
      "Epoch 131/1000\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 0.3652 - accuracy: 0.8705 - val_loss: 0.3571 - val_accuracy: 0.8714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17046d1548>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "model_fcnn.fit(x_TRAIN.values, y_TRAIN, batch_size=500,\n",
    "               validation_data=(x_VALID.values, y_VALID),\n",
    "                       callbacks=callbacks, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сохраняем полученную модель\n",
    "# model_fcnn.save_weights('fcnn_model_sdg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Загружаем веса модели из файла.\n",
    "# model_fcnn.load_weights('fcnn_model_sdg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График качества модели(метрика accuracy) на тренировочной и валидационной выборках в зависимости от количества эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='data\\fcnn_sgd_2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверяем качество на тестовой выборке__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.3578 - accuracy: 0.8727\n",
      "Полносвязная нейронная сеть(SGD) \n",
      "Accuracy на тестовой выборке равна: 0.8727\n"
     ]
    }
   ],
   "source": [
    "_, score = model_fcnn.evaluate(x_test.values, y_test_labels)\n",
    "print(\"Полносвязная нейронная сеть(SGD) \\nAccuracy на тестовой выборке равна: {0:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов полносвязная нейронная сеть показала лучший результат.\n",
    "Увеличив точность на тестовой выборке на  2.4%. Для этого ей понадобилось 130 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "x_TRAIN_reshaped = x_TRAIN.values.reshape(48000, 28, 28, 1)\n",
    "x_VALID_reshaped = x_VALID.values.reshape(12000, 28, 28, 1)\n",
    "x_TEST_reshaped = x_test.values.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простая сверточная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель\n",
    "model_cnn_1 = Sequential()\n",
    "model_cnn_1.add(Convolution2D(32, (3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model_cnn_1.add(MaxPooling2D((2,2)))\n",
    "model_cnn_1.add(Flatten())\n",
    "model_cnn_1.add(Dense(64, activation='relu'))\n",
    "model_cnn_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_1 = Sequential()\n",
    "model_cnn_1.add(tf.keras.layers.Convolution2D(32, (3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model_cnn_1.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model_cnn_1.add(tf.keras.layers.Convolution2D(64, (3,3), activation='relu'))\n",
    "model_cnn_1.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model_cnn_1.add(tf.keras.layers.Flatten())\n",
    "model_cnn_1.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model_cnn_1.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем callbacks\n",
    "# Остановка обучения если результат перестал улучшаться\n",
    "early_stopping =  EarlyStopping(patience=2, monitor='val_loss')\n",
    "# Tensorboard\n",
    "# profile_batch чтобы не выскакивала ошибка профилировщика\n",
    "tensorboard = TensorBoard(log_dir=f'Logs\\\\{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                          profile_batch = 100000000)\n",
    "callbacks = [early_stopping,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем процесс обучения\n",
    "model_cnn_1.compile(optimizer='adadelta',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель\n",
    "model_cnn_1.fit(x_TRAIN_reshaped, y_TRAIN, batch_size=500,\n",
    "                validation_data=(x_VALID_reshaped, y_VALID),\n",
    "                       callbacks=callbacks, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть с увеличенным количеством слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9a358d8cb025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Подготовка данных\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_TRAIN_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_TRAIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_VALID_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_VALID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_TEST_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "x_TRAIN_reshaped = x_TRAIN.values.reshape(48000, 28, 28, 1)\n",
    "x_VALID_reshaped = x_VALID.values.reshape(12000, 28, 28, 1)\n",
    "x_TEST_reshaped = x_test.values.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель и добавляем слои\n",
    "model_cnn_2 = Sequential()\n",
    "model_cnn_2.add(.Convolution2D(32, (3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model_cnn_2.add(MaxPooling2D((2,2)))\n",
    "model_cnn_2.add(Dropout(0.3))\n",
    "model_cnn_2.add(Dense(64,activation='relu'))\n",
    "model_cnn_2.add(Convolution2D(32),(3,3), activation='relu'))\n",
    "model_cnn_2.add(MaxPooling2D((2,2)))\n",
    "model_cnn_2.add(tf.Dropout(0.2))\n",
    "model_cnn_2.add(Dense(64, activation='relu'))\n",
    "model_cnn_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем процесс обучения\n",
    "model_cnn_2.compile(optimizer='adadelta',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем callbacks\n",
    "# Остановка обучения если результат перестал улучшаться\n",
    "early_stopping =  EarlyStopping(patience=3, monitor='val_loss')\n",
    "# Tensorboard\n",
    "# profile_batch чтобы не выскакивала ошибка профилировщика\n",
    "tensorboard = TensorBoard(log_dir=f'Logs\\\\{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "                          profile_batch = 100000000)\n",
    "callbacks = [early_stopping,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель\n",
    "model_cnn_2.fit(x_TRAIN_reshaped, y_TRAIN, batch_size=500,\n",
    "                validation_data=(x_VALID_reshaped, y_VALID),\n",
    "                       callbacks=callbacks, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная нейронная сеть с добавление Batch Normalization слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
