{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети. Основы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон - это модель, предложенная Френком Розенблаттом в 1957 году и являющаяся прообразом современных нейронных сетей. По своей сути она представляет из себя значительно упрощенную схему восприятия информации мозгом. Целью этого практического задания будет реализация собственной модели перцептрона. Давайте разберем схему работы этого алгоритма в деталях.\n",
    "\n",
    "* Мы работаем с тренировочной выборкой $S = \\{(x_i, y_i)| i \\in \\{1,...,m\\} \\}$\n",
    "* Инициализируем веса $\\omega^{(0)} \\leftarrow 0$ нулевым вектором.\n",
    "* Инициализирует bias параметр $b = 0$.\n",
    "* В начальный момент времени номер шага $t=0$.\n",
    "* Задаем learning rate $\\eta > 0$.\n",
    "* Пока значение $t < t_{\\max}$\n",
    "    * случайно выбираем объект из тренировочной выборки $(x_i, y_i) \\in S$.\n",
    "    * если выполняется условие $y_i (\\langle \\omega^{(t)}, x_i\\rangle + b) \\leq 0$ тогда\n",
    "        * $b^{(t+1)} \\leftarrow b^{(t)} + \\eta \\times y_i$.\n",
    "        * $\\omega^{(t+1)} \\leftarrow \\omega^{(t)} + \\eta \\times y_i \\times x_i$.\n",
    "    * далее, обновляем $t \\leftarrow t+1$.\n",
    "\n",
    "Таким образом, финальное значение ветора весов $\\omega$ и bias параметра $b$ позволяют классифицировать новый объект $x$. Если $(\\langle \\omega, x \\rangle + b) \\geq 0$, то мы относим объект к классу $+1$, в противном случае мы относим объект к классу $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим датасет для задачи классификации цветков Ириса с помощь функции `load_iris` из `sklearn.datasets`. Давайте подготовим данные для задачи бинарной классификации. Для этого выберем первые 100 элементов из данного набора данных. Так же преобразуем класс $0$ в класс $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X, y = X[:100], y[:100]\n",
    "num_features = X.shape[1]\n",
    "y = np.array([1 if y_i == 1 else -1 for y_i in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм перцептрона приведенный выше. Для выборки случайного объекта из тренировочного датасета по индексу используйте функцию `randint` из модуля `random` с параметрами 0 и n, где n - это размер тренировочно выборки. Перед запуском итераций алгоритма установите `random.seed(42)`. Вы можете реализовать перцептрон в качестве класса с интерфейсом, похожим на интерфейсы моделей из `scikit-learn`. Для этого достаточно реализовать функцию `fit` и `predict` для решения этого практического задания. Однако, ваша реализация может отличаться. Необходимое требование - это использование генератора случайных чисел, описанного выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, nu, t_max):\n",
    "        self.nu = nu\n",
    "        self.t_max = t_max\n",
    "\n",
    "        self.w = [0, 0, 0, 0]\n",
    "        \n",
    "        self.b = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        random.seed(42)\n",
    "        n = len(X)\n",
    "\n",
    "        t = 0\n",
    "        while t < self.t_max:\n",
    "            rnd_index = random.randint(0, n - 1)\n",
    "\n",
    "            tmp_X = X[rnd_index]\n",
    "            tmp_y = y[rnd_index]\n",
    "\n",
    "            if tmp_y * (np.dot(tmp_X, self.w) + self.b) <= 0:\n",
    "                self.b += self.nu * tmp_y\n",
    "\n",
    "                for i in range(len(self.w)):\n",
    "                    self.w[i] += self.nu * tmp_y * tmp_X[i]\n",
    "\n",
    "            t += 1\n",
    "\n",
    "    def predict(self, X):\n",
    "        out_y = []\n",
    "\n",
    "        for x in X:\n",
    "            if np.dot(x, self.w) + self.b >= 0:\n",
    "                out_y.append(1)\n",
    "            else:\n",
    "                out_y.append(-1)\n",
    "\n",
    "        return out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self,rate,t_max):\n",
    "        self.rate = rate\n",
    "        self.t_max = t_max\n",
    "        # Создаем нулевой вектор нужной длины\n",
    "        self.w = np.zeros(4)\n",
    "        # Устанавливаем начальное смещение\n",
    "        self.b = 0\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        # Устанавливаем параметры генератора рандомных чисел\n",
    "        random.seed(42)\n",
    "        # Длина массива\n",
    "        n = len(X_train)\n",
    "        # Номер шага\n",
    "        t = 0\n",
    "        while t < self.t_max:\n",
    "            index = random.randint(0,n-1)\n",
    "            \n",
    "            # Сохраняем в переменные нужные вектора\n",
    "            # в chosen_X находится список из 4 признаков\n",
    "            # в chosen_y целевой признак 1 или -1\n",
    "            chosen_X = X_train[index]\n",
    "            chosen_y = y_train[index]\n",
    "            # Перемножаем 2 вектора(не забывай что это будет скалярное произведение)\n",
    "            if chosen_y * (np.dot(chosen_X,self.w) + self.b) <= 0:\n",
    "                self.b = self.rate * chosen_y\n",
    "                \n",
    "                for i in range(len(self.w)):\n",
    "                    self.w[i] += self.rate*chosen_y*chosen_X[i]\n",
    "            t += 1\n",
    "             if tmp_y * (np.dot(tmp_X, self.w) + self.b) <= 0:\n",
    "                self.b += self.nu * tmp_y\n",
    "\n",
    "                for i in range(len(self.w)):\n",
    "                    self.w[i] += self.nu * tmp_y * tmp_X[i]\n",
    "\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        predicted = []\n",
    "        # Перебираем тестовую выборку\n",
    "        \n",
    "        for x in X_test:\n",
    "            if np.dot(x,self.w)+self.b >=0:\n",
    "                predicted.append(1)\n",
    "            else:\n",
    "                predicted.append(-1)\n",
    "        return predicted\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом является проверка нашей модели. Случайно разделите выборку на тренировочный и тестовый датасет, используя функцию `tran_test_split` с параметрами `test_size=0.25` и `random_state=10`. Запустите обучение модели с параметрами $\\eta=0.1$ и $t_{\\max}=40$. Оцените качество на тестовой выборке и запишите результат в переменную `score` с точность до двух знаков после запятой, используя метрику `accuracy`. Это значение и будет являться ответом на это практическое задание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "model = Perceptron(0.1, 40)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score = round(accuracy_score(y_test, y_pred), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.19999999999999996,\n",
       " -0.8900000000000003,\n",
       " 1.2600000000000005,\n",
       " 0.5099999999999999]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-0.19999999999999996,\n",
    " -0.8900000000000003,\n",
    " 1.2600000000000005,\n",
    " 0.5099999999999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"score {0:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
